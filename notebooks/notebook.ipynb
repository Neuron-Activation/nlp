{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import os\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset, random_split\n","import re\n","from nltk.corpus import stopwords"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Загрузка данных\n","train_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\")\n","test_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Предобработка текста\n","stop_words = set(stopwords.words('english'))\n","\n","def clean_text(text):\n","    text = re.sub(r'[^\\w\\s]', '', text)\n","    words = text.split()  # Tokenize\n","    words = [word.lower() for word in words if word.isalpha()]\n","    words = [word for word in words if word not in stop_words]\n","    return ' '.join(words)\n","\n","train_essays['clean_text'] = train_essays['text'].apply(clean_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Разделение данных\n","X_train, X_val, y_train, y_val = train_test_split(train_essays['clean_text'], train_essays['generated'], test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Токенизация для BERT\n","tokenizer = BertTokenizer.from_pretrained('/kaggle/input/bert-base-uncased/bert-base-uncased', do_lower_case=True, padding=True, truncation=True, max_length=128)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["encoded_train = tokenizer(X_train.tolist(), padding=True, truncation=True, return_tensors='pt')\n","encoded_val = tokenizer(X_val.tolist(), padding=True, truncation=True, return_tensors='pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Преобразование меток в тензоры\n","train_labels = torch.tensor(y_train.values)\n","val_labels = torch.tensor(y_val.values)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Создание TensorDatasets\n","train_dataset = TensorDataset(encoded_train['input_ids'], encoded_train['attention_mask'], train_labels)\n","val_dataset = TensorDataset(encoded_val['input_ids'], encoded_val['attention_mask'], val_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# DataLoader для эффективной обработки\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Определение модели BERT для классификации последовательностей\n","model = BertForSequenceClassification.from_pretrained('/kaggle/input/bert-base-uncased/bert-base-uncased', num_labels=2)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Определение оптимизатора и планировщика скорости обучения\n","optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n","epochs = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Цикл обучения\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    for batch in train_loader:\n","        input_ids, attention_mask, labels = batch\n","        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","\n","    avg_train_loss = total_loss / len(train_loader)\n","    print(f\"Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss:.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Цикл валидации\n","model.eval()\n","val_preds = []\n","val_labels = []\n","\n","with torch.no_grad():\n","    for batch in val_loader:\n","        input_ids, attention_mask, labels = batch\n","        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n","\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","\n","        val_preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n","        val_labels.extend(labels.cpu().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Расчет точности валидации\n","val_accuracy = accuracy_score(val_labels, val_preds)\n","print(f\"Validation Accuracy: {val_accuracy:.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Обработка тестовых данных\n","test_inputs = tokenizer(test_essays['text'].tolist(), padding=True, truncation=True, return_tensors='pt')\n","\n","# Перемещение входного тензора на то же устройство, что и модель\n","test_inputs = {key: value.to(device) for key, value in test_inputs.items()}\n","\n","with torch.no_grad():\n","    outputs = model(**test_inputs)\n","    logits = outputs.logits\n","    \n","predictions = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()\n","\n","submission = pd.DataFrame({\n","    'id': test_essays['id'],\n","    'generated': predictions\n","})\n","\n","submission.to_csv('/kaggle/working/submission.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7516023,"sourceId":61542,"sourceType":"competition"},{"datasetId":4943518,"sourceId":8322071,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
